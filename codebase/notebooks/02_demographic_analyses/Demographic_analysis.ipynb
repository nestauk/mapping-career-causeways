{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic analysis\n",
    "\n",
    "This notebook features the analysis of the EU LFS microdata. While we have included it in the repository for the sake of completeness, we are not able to share input microdata and hence it will not be possible to independently replicate these particular results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_risk_cat2(some_row):\n",
    "    '''\n",
    "    \n",
    "High risk: r == 3, b == 0\n",
    "Low risk: r == 0, b == 3\n",
    "\n",
    "Categories:\n",
    "0 - High risk\n",
    "1 - Low risk\n",
    "2 - Other\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if some_row['risk_q'] == 3 and some_row['bottleneck_q'] == 0:\n",
    "        res = 0\n",
    "    elif some_row['risk_q'] == 0 and some_row['bottleneck_q'] == 3:\n",
    "        res = 1\n",
    "    else:\n",
    "        res = 2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = useful_paths.codebase_dir\n",
    "eurostat_dir = 'n/a' # Can't share the microdata\n",
    "eurostat_output_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate automation risk estimates at ISCO 3-digit and 4-digit level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sml = pd.read_csv(os.path.join(base_dir, 'data/interim/automation_analysis', 'agg_job_task_scores_esco_revised_w_no_phys_bott.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>id</th>\n",
       "      <th>esco_occupation</th>\n",
       "      <th>isco_code</th>\n",
       "      <th>weighted_risk</th>\n",
       "      <th>high_risk</th>\n",
       "      <th>low_risk</th>\n",
       "      <th>weight_enablers</th>\n",
       "      <th>weight_bottlenecks</th>\n",
       "      <th>weight_phys_bottlenecks</th>\n",
       "      <th>bottleneck_q</th>\n",
       "      <th>risk_q</th>\n",
       "      <th>risk_cat</th>\n",
       "      <th>risk_cat_label</th>\n",
       "      <th>not_phys_weighted_risk</th>\n",
       "      <th>not_phys_bottlenecks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>chief executives</td>\n",
       "      <td>1104</td>\n",
       "      <td>member of parliament</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>3.49985</td>\n",
       "      <td>0.563389</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>0.962482</td>\n",
       "      <td>0.356627</td>\n",
       "      <td>0.163575</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.548024</td>\n",
       "      <td>0.193053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>chief executives</td>\n",
       "      <td>1111</td>\n",
       "      <td>secretary general</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>3.49985</td>\n",
       "      <td>0.563389</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>0.962482</td>\n",
       "      <td>0.356627</td>\n",
       "      <td>0.163575</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.548024</td>\n",
       "      <td>0.193053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>chief executives</td>\n",
       "      <td>1288</td>\n",
       "      <td>chief executive officer</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>3.49985</td>\n",
       "      <td>0.563389</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>0.962482</td>\n",
       "      <td>0.356627</td>\n",
       "      <td>0.163575</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>3.548024</td>\n",
       "      <td>0.193053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code             Title    id          esco_occupation  isco_code  \\\n",
       "0     11-1011.00  chief executives  1104     member of parliament     1111.0   \n",
       "1     11-1011.00  chief executives  1111        secretary general     1112.0   \n",
       "2     11-1011.00  chief executives  1288  chief executive officer     1120.0   \n",
       "\n",
       "   weighted_risk  high_risk  low_risk  weight_enablers  weight_bottlenecks  \\\n",
       "0        3.49985   0.563389  0.436611         0.962482            0.356627   \n",
       "1        3.49985   0.563389  0.436611         0.962482            0.356627   \n",
       "2        3.49985   0.563389  0.436611         0.962482            0.356627   \n",
       "\n",
       "   weight_phys_bottlenecks  bottleneck_q  risk_q  risk_cat risk_cat_label  \\\n",
       "0                 0.163575             0       2         2          Other   \n",
       "1                 0.163575             0       2         2          Other   \n",
       "2                 0.163575             0       2         2          Other   \n",
       "\n",
       "   not_phys_weighted_risk  not_phys_bottlenecks  \n",
       "0                3.548024              0.193053  \n",
       "1                3.548024              0.193053  \n",
       "2                3.548024              0.193053  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sml.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sml['isco_code'] = sml['isco_code'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sml['isco_3d'] = sml['isco_code'].apply(lambda x: x[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Calculate risk using a combination of weighted risk and proportion of bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_3d_risk = sml.groupby('isco_3d')[['weighted_risk', 'weight_bottlenecks']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_3d_risk['risk_q'] = pd.qcut(isco_3d_risk['weighted_risk'], 4, labels=False)\n",
    "isco_3d_risk['bottleneck_q'] = pd.qcut(isco_3d_risk['weight_bottlenecks'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_3d_risk['risk_cat'] = isco_3d_risk.apply(assign_risk_cat2, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_risk</th>\n",
       "      <th>weight_bottlenecks</th>\n",
       "      <th>risk_q</th>\n",
       "      <th>bottleneck_q</th>\n",
       "      <th>risk_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isco_3d</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3.501665</td>\n",
       "      <td>0.358990</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3.486389</td>\n",
       "      <td>0.295306</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3.464577</td>\n",
       "      <td>0.404742</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         weighted_risk  weight_bottlenecks  risk_q  bottleneck_q  risk_cat\n",
       "isco_3d                                                                   \n",
       "111           3.501665            0.358990       2             0         2\n",
       "112           3.486389            0.295306       2             0         2\n",
       "121           3.464577            0.404742       1             0         2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isco_3d_risk.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save risk estimates at 3-d ISCO as a dict\n",
    "isco_risk_cat = dict()\n",
    "for ix, row in isco_3d_risk.iterrows():\n",
    "    isco_risk_cat[ix] = row['risk_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isco_risk_cat['931']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_risk_cat['224'] = 2 #appears to be unmapped to O*NET occupations and thus missing from earlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(framework_dir, 'isco_risk_cat'), 'wb') as f:\n",
    "#    pickle.dump(isco_risk_cat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above but for 4-d ISCO\n",
    "isco_4d_risk = sml.groupby('isco_code')[['weighted_risk', 'weight_bottlenecks']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_4d_risk['risk_q'] = pd.qcut(isco_4d_risk['weighted_risk'], 4, labels=False)\n",
    "isco_4d_risk['bottleneck_q'] = pd.qcut(isco_4d_risk['weight_bottlenecks'], 4, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_4d_risk['risk_cat'] = isco_4d_risk.apply(assign_risk_cat2, axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Save risk estimates at 3-digit and 4-digit ISCO group level; add group titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_titles = pd.read_excel(os.path.join('lookups', 'struct08.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_titles['isco_code'] = isco_titles['isco_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create isco title lookup dict\n",
    "isco_titles_dict = {}\n",
    "for ix, row in isco_titles.iterrows():\n",
    "    isco_titles_dict[row['isco_code']] = row['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add minor group title (e.g. mg_title)\n",
    "isco_3d_risk['mg_title'] = isco_3d_risk.index.map(lambda x: isco_titles_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 3-d ISCO occupations in high risk category\n",
    "#isco_3d_risk[isco_3d_risk['risk_cat'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unit group title (e.g. ug_title)\n",
    "isco_4d_risk['ug_title'] = isco_4d_risk.index.map(lambda x: isco_titles_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 4-d ISCO occupations in high risk category\n",
    "#isco_4d_risk[isco_4d_risk['risk_cat'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_4d_risk.to_csv(os.path.join(base_dir, 'data/interim/automation_analysis', 'isco_4d_risk.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_3d_risk.to_csv(os.path.join(base_dir, 'data/interim/automation_analysis', 'isco_3d_risk.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analyse Eurostat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Clean LFS files and study breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(input_df):\n",
    "    '''\n",
    "    Duplicates: remove duplicates (combination of household id, household member number and survey wave).\n",
    "    ISCO3D: Remove entries with no ISCO3D (this will remove those younger than 15); \n",
    "    recode ISCO3D first as int then as str. Remove entries with ISCO3D equal to '999' \n",
    "    (this will filter out inactive and unemployed) and those with values with fewer than 3 digits.\n",
    "    AGE: Remove entries with people older than 75 (75-79 age band, shown in EU LFS as age 77)\n",
    "    '''\n",
    "    #drop duplicates\n",
    "    input_df_unique = input_df.drop_duplicates(subset = ['HHNUM', 'HHSEQNUM','QUARTER', 'REM'])\n",
    "    \n",
    "    #choose subset of columns\n",
    "    input_df_unique = input_df_unique[['HHNUM', 'AGE', 'SEX', 'REGION', \n",
    "                           'ILOSTAT', 'STAPRO', 'NACE1D', 'ISCO3D', 'HATLEV1D',\n",
    "                          'INCDECIL', 'NATIONAL', 'FTPT', 'TEMP', 'TEMPDUR', 'COEFF']]\n",
    "    \n",
    "    #ensure that ISCO3D is a string with len == 3 (need to remove missing values first)\n",
    "    input_df_unique.dropna(subset = ['ISCO3D'], inplace = True)\n",
    "    input_df_unique['ISCO3D'] = input_df_unique['ISCO3D'].astype(int).astype(str)\n",
    "        \n",
    "    #remove entries equal to '999', '200' and those with fewer than 3 digits\n",
    "    input_df_filtered = input_df_unique[input_df_unique['ISCO3D'] !='999']\n",
    "    input_df_filtered = input_df_filtered[input_df_filtered['ISCO3D'] !='200']\n",
    "    input_df_filtered = input_df_filtered[input_df_filtered['ISCO3D'] !='330']\n",
    "    input_df_filtered = input_df_filtered[input_df_filtered['ISCO3D'] !='230']\n",
    "    input_df_filtered = input_df_filtered[~(input_df_filtered.ISCO3D.str.len() <3)]\n",
    "        \n",
    "    #filter out people older than 77\n",
    "    input_df_filtered = input_df_filtered[input_df_filtered['AGE'] <=77]\n",
    "        \n",
    "    return input_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_breakdown(input_df, groupby_var, risk_var, agg_var):\n",
    "    '''\n",
    "    Produce breakdown of a given dataframe by a specified demographic variable and by risk category both \n",
    "    a) as proportions and\n",
    "    b) as counts (employment in thousands)\n",
    "    '''\n",
    "    breakdown = input_df.groupby([groupby_var, risk_var])[agg_var].sum()\n",
    "    group_totals = input_df.groupby(groupby_var)[agg_var].sum()\n",
    "    breakdown_prop = breakdown/group_totals*100\n",
    "    return breakdown, breakdown_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_breakdown(input_df, vals, index_var, column_var, thousands=False):\n",
    "    '''\n",
    "    Produce contingency table for chi-square analysis\n",
    "    '''\n",
    "    input_df = input_df.reset_index()\n",
    "    if thousands:\n",
    "        input_df['COEFF'] = input_df['COEFF']*1000\n",
    "    input_df[['RISK_CAT', 'COEFF']] = input_df[['RISK_CAT', 'COEFF']].astype(int)\n",
    "    pivot_df = pd.pivot_table(input_df, values= vals, index=[index_var],\n",
    "                    columns=[column_var])\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bring it all together for all years\n",
    "\n",
    "#Generate list of files in folder\n",
    "#file_list = os.listdir(os.path.join(eurostat_dir, 'Yearly','UK_YEAR_1998_onwards'))\n",
    "file_list = os.listdir(os.path.join(eurostat_dir, 'Yearly','IT_YEAR_1998_onwards'))\n",
    "# file_list = os.listdir(os.path.join(eurostat_dir, 'Yearly','FR_YEAR_1998_onwards'))\n",
    "\n",
    "#Define demographic variables to explore\n",
    "demographic_vars = ['SEX', 'AGE', 'REGION', 'NACE1D', 'HATLEV1D','INCDECIL', 'NATIONAL', 'FTPT', 'TEMP']\n",
    "\n",
    "#Define output dicts for storing results\n",
    "breakdown_props = collections.defaultdict(dict)\n",
    "breakdown_counts = collections.defaultdict(dict)\n",
    "chi_square_res = collections.defaultdict(dict)\n",
    "df_chunks = []\n",
    "\n",
    "#Iterate over files in the folder\n",
    "for file in file_list:\n",
    "    year = file[2:6]\n",
    "    \n",
    "    print(year)\n",
    "    \n",
    "#    year_file = pd.read_csv(os.path.join(eurostat_dir, 'Yearly','UK_YEAR_1998_onwards', file))\n",
    "    year_file = pd.read_csv(os.path.join(eurostat_dir, 'Yearly','IT_YEAR_1998_onwards', file))\n",
    "#     year_file = pd.read_csv(os.path.join(eurostat_dir, 'Yearly','FR_YEAR_1998_onwards', file))\n",
    "    filtered_df = filter_df(year_file)\n",
    "    filtered_df['RISK_CAT'] = filtered_df['ISCO3D'].apply(lambda x: isco_risk_cat[x])\n",
    "    filtered_df['YEAR'] = year\n",
    "    \n",
    "    df_chunks.append(filtered_df)\n",
    "\n",
    "\n",
    "    for demographic_var in demographic_vars:\n",
    "        print(demographic_var)\n",
    "        breakdown_count, breakdown_prop = demo_breakdown(filtered_df, demographic_var, 'RISK_CAT', 'COEFF')\n",
    "        breakdown_counts[year][demographic_var] = breakdown_count\n",
    "        breakdown_props[year][demographic_var] = breakdown_prop\n",
    "\n",
    "        breakdown_p = pivot_breakdown(breakdown_count, 'COEFF', demographic_var, 'RISK_CAT', True)\n",
    "        #This is condition for chi-square test, which requires at least 5 observations in each group\n",
    "        #WARNING: given that numbers are in thousands, the threshold could have been 0.005, so technically \n",
    "        #we could have run chi-square on more demographic breakdowns than we did for the report\n",
    "        check_condition = (breakdown_p >=5).all(axis = 1).all() \n",
    "        print(check_condition)\n",
    "\n",
    "        if check_condition:\n",
    "            stat, p, dof, expected = chi2_contingency(breakdown_p.values)\n",
    "\n",
    "        else:\n",
    "            stat = np.nan\n",
    "            p = np.nan\n",
    "\n",
    "        print(stat,p)\n",
    "        chi_square_res[year][demographic_var] = (stat, p)\n",
    "        \n",
    "all_years = pd.concat(df_chunks)        \n",
    "        \n",
    "#Save outputs\n",
    "#with open(os.path.join(eurostat_output_dir, 'uk_breakdown_props_r_KK.pkl'), 'wb') as f:\n",
    "#    pickle.dump(breakdown_props, f)\n",
    "    \n",
    "#with open(os.path.join(eurostat_output_dir, 'uk_chi_square_res_r_KK.pkl'), 'wb') as f:\n",
    "#    pickle.dump(chi_square_res, f)  \n",
    "    \n",
    "#all_years.to_pickle(os.path.join(eurostat_output_dir, 'uk_all_years_r_KK.pkl'))\n",
    "\n",
    "#Save outputs\n",
    "with open(os.path.join(eurostat_output_dir, 'ita_breakdown_props_r_KK.pkl'), 'wb') as f:\n",
    "    pickle.dump(breakdown_props, f)\n",
    "    \n",
    "with open(os.path.join(eurostat_output_dir, 'ita_chi_square_res_r_KK.pkl'), 'wb') as f:\n",
    "    pickle.dump(chi_square_res, f)  \n",
    "    \n",
    "all_years.to_pickle(os.path.join(eurostat_output_dir, 'ita_all_years_r_KK.pkl'))\n",
    "\n",
    "#Save outputs\n",
    "# with open(os.path.join(eurostat_output_dir, 'fra_breakdown_counts_r_KK.pkl'), 'wb') as f:\n",
    "#     pickle.dump(breakdown_counts, f)\n",
    "\n",
    "# with open(os.path.join(eurostat_output_dir, 'fra_breakdown_props_r_KK.pkl'), 'wb') as f:\n",
    "#     pickle.dump(breakdown_props, f)\n",
    "    \n",
    "# with open(os.path.join(eurostat_output_dir, 'fra_chi_square_res_r_KK.pkl'), 'wb') as f:\n",
    "#     pickle.dump(chi_square_res, f)  \n",
    "    \n",
    "# all_years.to_pickle(os.path.join(eurostat_output_dir, 'fra_all_years_r_KK.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Proportion of workers by risk category by all demographic variables at a national level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra_combined_breakdown_sex_r.csv\n",
      "fra_combined_breakdown_age_r.csv\n",
      "fra_combined_breakdown_region_r.csv\n",
      "fra_combined_breakdown_nace1d_r.csv\n",
      "fra_combined_breakdown_hatlev1d_r.csv\n",
      "fra_combined_breakdown_incdecil_r.csv\n",
      "fra_combined_breakdown_national_r.csv\n",
      "fra_combined_breakdown_ftpt_r.csv\n",
      "fra_combined_breakdown_temp_r.csv\n"
     ]
    }
   ],
   "source": [
    "#Combine breakdowns (as proportions) over 5 year period\n",
    "for demographic_var in demographic_vars:\n",
    "    chunks = []\n",
    "    for k in breakdown_props.keys():\n",
    "        chunks.append(breakdown_props[k][demographic_var])\n",
    "\n",
    "    combined_chunks = pd.concat(chunks, axis =1)\n",
    "    combined_chunks.columns = breakdown_props.keys()\n",
    "\n",
    "    df_name = demographic_var.lower()\n",
    "#    df_file_name = 'uk_combined_breakdown'+'_'+df_name+'_r'+'.'+'csv'\n",
    "#    df_file_name = 'ita_combined_breakdown'+'_'+df_name+'_r'+'.'+'csv'\n",
    "    df_file_name = 'fra_combined_breakdown'+'_'+df_name+'_r'+'.'+'csv'\n",
    "\n",
    "\n",
    "    print(df_file_name)\n",
    "\n",
    "    combined_chunks.to_csv(os.path.join(eurostat_output_dir, df_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Employment (thousands) by 3-digit ISCO occupations at national level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#National breakdown by 3d ISCO\n",
    "country_file = 'fra_all_years_r.pkl'#'ita_all_years_r.pkl' #'uk_all_years_r.pkl'\n",
    "country = pd.read_pickle(os.path.join(eurostat_output_dir, 'all_years_lfs', country_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHNUM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ILOSTAT</th>\n",
       "      <th>STAPRO</th>\n",
       "      <th>NACE1D</th>\n",
       "      <th>ISCO3D</th>\n",
       "      <th>HATLEV1D</th>\n",
       "      <th>INCDECIL</th>\n",
       "      <th>NATIONAL</th>\n",
       "      <th>FTPT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMPDUR</th>\n",
       "      <th>COEFF</th>\n",
       "      <th>RISK_CAT</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368040</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>J</td>\n",
       "      <td>251</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001-EU15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>368041</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I</td>\n",
       "      <td>524</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368044</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>235</td>\n",
       "      <td>M</td>\n",
       "      <td>99.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HHNUM  AGE  SEX REGION  ILOSTAT  STAPRO NACE1D ISCO3D HATLEV1D  INCDECIL  \\\n",
       "0  368040   32    1     10        1     3.0      J    251        H       NaN   \n",
       "1  368041   22    2     10        1     3.0      I    524        H       NaN   \n",
       "4  368044   17    1     10        1     0.0      P    235        M      99.0   \n",
       "\n",
       "          NATIONAL  FTPT  TEMP  TEMPDUR  COEFF  RISK_CAT  YEAR  \n",
       "0         001-EU15     1     2      4.0    0.0       2.0  2014  \n",
       "1  000-OWN COUNTRY     2     2      1.0    0.0       0.0  2014  \n",
       "4  000-OWN COUNTRY     2     9      9.0    0.0       2.0  2014  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country[country.YEAR=='2015'].COEFF.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHNUM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ILOSTAT</th>\n",
       "      <th>STAPRO</th>\n",
       "      <th>NACE1D</th>\n",
       "      <th>ISCO3D</th>\n",
       "      <th>HATLEV1D</th>\n",
       "      <th>INCDECIL</th>\n",
       "      <th>NATIONAL</th>\n",
       "      <th>FTPT</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>TEMPDUR</th>\n",
       "      <th>COEFF</th>\n",
       "      <th>RISK_CAT</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106924</th>\n",
       "      <td>475899</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Y1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>G</td>\n",
       "      <td>522</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.07933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107037</th>\n",
       "      <td>475952</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>Y1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>911</td>\n",
       "      <td>L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.09959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107218</th>\n",
       "      <td>476026</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Y1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>O</td>\n",
       "      <td>962</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.06342</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107320</th>\n",
       "      <td>476068</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>Y1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>P</td>\n",
       "      <td>232</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.07783</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107321</th>\n",
       "      <td>476068</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Y1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>G</td>\n",
       "      <td>522</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.07783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503708</th>\n",
       "      <td>511263</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Y3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>522</td>\n",
       "      <td>L</td>\n",
       "      <td>99.0</td>\n",
       "      <td>012-EAST ASIA</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.07983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503713</th>\n",
       "      <td>511265</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Y3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>O</td>\n",
       "      <td>411</td>\n",
       "      <td>H</td>\n",
       "      <td>6.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.09062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503724</th>\n",
       "      <td>511267</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>Y3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>O</td>\n",
       "      <td>234</td>\n",
       "      <td>H</td>\n",
       "      <td>10.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.04943</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503746</th>\n",
       "      <td>511272</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>Y3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>751</td>\n",
       "      <td>H</td>\n",
       "      <td>99.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503747</th>\n",
       "      <td>511272</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>Y3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>221</td>\n",
       "      <td>H</td>\n",
       "      <td>10.0</td>\n",
       "      <td>000-OWN COUNTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HHNUM  AGE  SEX REGION  ILOSTAT  STAPRO NACE1D ISCO3D HATLEV1D  \\\n",
       "106924  475899   22    1     Y1        1     3.0      G    522        M   \n",
       "107037  475952   37    2     Y1        1     3.0      Q    911        L   \n",
       "107218  476026   22    1     Y1        1     3.0      O    962        M   \n",
       "107320  476068   47    2     Y1        1     3.0      P    232        H   \n",
       "107321  476068   22    1     Y1        1     3.0      G    522        M   \n",
       "...        ...  ...  ...    ...      ...     ...    ...    ...      ...   \n",
       "503708  511263   37    1     Y3        1     0.0      G    522        L   \n",
       "503713  511265   37    1     Y3        1     3.0      O    411        H   \n",
       "503724  511267   47    2     Y3        1     3.0      O    234        H   \n",
       "503746  511272   47    2     Y3        1     0.0      C    751        H   \n",
       "503747  511272   47    1     Y3        1     3.0      Q    221        H   \n",
       "\n",
       "        INCDECIL         NATIONAL  FTPT  TEMP  TEMPDUR    COEFF  RISK_CAT  \\\n",
       "106924       2.0  000-OWN COUNTRY     1     2      6.0  0.07933       0.0   \n",
       "107037       1.0  000-OWN COUNTRY     2     1      9.0  0.09959       1.0   \n",
       "107218       3.0  000-OWN COUNTRY     1     2      7.0  0.06342       2.0   \n",
       "107320       1.0  000-OWN COUNTRY     2     2      2.0  0.07783       2.0   \n",
       "107321       1.0  000-OWN COUNTRY     2     2      3.0  0.07783       0.0   \n",
       "...          ...              ...   ...   ...      ...      ...       ...   \n",
       "503708      99.0    012-EAST ASIA     1     9      9.0  0.07983       0.0   \n",
       "503713       6.0  000-OWN COUNTRY     1     1      9.0  0.09062       0.0   \n",
       "503724      10.0  000-OWN COUNTRY     1     1      9.0  0.04943       2.0   \n",
       "503746      99.0  000-OWN COUNTRY     2     9      9.0  0.07550       2.0   \n",
       "503747      10.0  000-OWN COUNTRY     1     1      9.0  0.07550       2.0   \n",
       "\n",
       "        YEAR  \n",
       "106924  2015  \n",
       "107037  2015  \n",
       "107218  2015  \n",
       "107320  2015  \n",
       "107321  2015  \n",
       "...      ...  \n",
       "503708  2015  \n",
       "503713  2015  \n",
       "503724  2015  \n",
       "503746  2015  \n",
       "503747  2015  \n",
       "\n",
       "[491 rows x 17 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country[(country.YEAR=='2015') & (country.COEFF<0.10) & (country.COEFF>0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "isco_chunks = []\n",
    "years = []\n",
    "for name, group in country.groupby('YEAR'):\n",
    "    print(name)\n",
    "    isco_breakdown = group.groupby('ISCO3D')['COEFF'].sum()\n",
    "#    isco_breakdown = isco_breakdown*1000\n",
    "    isco_breakdown.fillna(0, inplace = True)\n",
    "    isco_breakdown = isco_breakdown.round(3)\n",
    "    isco_chunks.append(isco_breakdown)\n",
    "    years.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_chunks_combined = pd.concat(isco_chunks, axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "isco_chunks_combined.columns = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#isco_chunks_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_output_file = 'ita_breakdown_by_isco.csv'#'uk_breakdown_by_isco.csv' #'fra_breakdown_by_isco.csv'\n",
    "isco_chunks_combined.to_csv(os.path.join(eurostat_output_dir, country_output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Combine employment data with risk estimates and occupational group titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in breakdown by ISCO\n",
    "#country_file = 'uk_breakdown_by_isco.csv'\n",
    "#country_file = 'ita_breakdown_by_isco.csv'\n",
    "country_file = 'fra_breakdown_by_isco.csv'\n",
    "\n",
    "country_isco_breakdown = pd.read_csv(os.path.join(eurostat_output_dir, 'nat_breakdown_by_isco', country_file), \n",
    "                                     index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_isco_breakdown.index = country_isco_breakdown.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_isco_breakdown2 = country_isco_breakdown.merge(isco_3d_risk[['mg_title', 'risk_cat']], \n",
    "                                                       left_index = True,\n",
    "                                                      right_on = 'isco_3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_file2 = 'uk_breakdown_by_isco_w_risk.csv'\n",
    "#country_file2 = 'ita_breakdown_by_isco_w_risk.csv'\n",
    "country_file2 = 'fra_breakdown_by_isco_w_risk.csv'\n",
    "\n",
    "#country_isco_breakdown2.to_csv(os.path.join(eurostat_output_dir, 'nat_breakdown_by_isco', country_file2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Employment by risk category by all demographic variables at a national level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "SEX\n",
      "AGE\n",
      "REGION\n",
      "NACE1D\n",
      "HATLEV1D\n",
      "INCDECIL\n",
      "NATIONAL\n",
      "FTPT\n",
      "TEMP\n",
      "2015\n",
      "SEX\n",
      "AGE\n",
      "REGION\n",
      "NACE1D\n",
      "HATLEV1D\n",
      "INCDECIL\n",
      "NATIONAL\n",
      "FTPT\n",
      "TEMP\n",
      "2016\n",
      "SEX\n",
      "AGE\n",
      "REGION\n",
      "NACE1D\n",
      "HATLEV1D\n",
      "INCDECIL\n",
      "NATIONAL\n",
      "FTPT\n",
      "TEMP\n",
      "2017\n",
      "SEX\n",
      "AGE\n",
      "REGION\n",
      "NACE1D\n",
      "HATLEV1D\n",
      "INCDECIL\n",
      "NATIONAL\n",
      "FTPT\n",
      "TEMP\n",
      "2018\n",
      "SEX\n",
      "AGE\n",
      "REGION\n",
      "NACE1D\n",
      "HATLEV1D\n",
      "INCDECIL\n",
      "NATIONAL\n",
      "FTPT\n",
      "TEMP\n"
     ]
    }
   ],
   "source": [
    "#Define demographic variables to explore\n",
    "demographic_vars = ['SEX', 'AGE', 'REGION', 'NACE1D', 'HATLEV1D','INCDECIL', 'NATIONAL', 'FTPT', 'TEMP']\n",
    "\n",
    "#Define output dicts for storing results\n",
    "breakdown_counts = collections.defaultdict(dict)\n",
    "\n",
    "#Iterate over files in the folder\n",
    "for name, group in country.groupby('YEAR'):\n",
    "    print(name)\n",
    "    \n",
    "    for demographic_var in demographic_vars:\n",
    "        print(demographic_var)\n",
    "        breakdown_count, breakdown_prop = demo_breakdown(group, demographic_var, 'RISK_CAT', 'COEFF')\n",
    "        breakdown_counts[name][demographic_var] = breakdown_count  \n",
    "        \n",
    "#Save outputs\n",
    "country_breakdown_output_file = 'ita_breakdown_counts_r.pkl' #'uk_breakdown_counts_r.pkl' #'fra_breakdown_counts_r.pkl'\n",
    "with open(os.path.join(eurostat_output_dir, country_breakdown_output_file), 'wb') as f:\n",
    "    pickle.dump(breakdown_counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ita_combined_breakdown_k_sex.csv\n",
      "ita_combined_breakdown_k_age.csv\n",
      "ita_combined_breakdown_k_region.csv\n",
      "ita_combined_breakdown_k_nace1d.csv\n",
      "ita_combined_breakdown_k_hatlev1d.csv\n",
      "ita_combined_breakdown_k_incdecil.csv\n",
      "ita_combined_breakdown_k_national.csv\n",
      "ita_combined_breakdown_k_ftpt.csv\n",
      "ita_combined_breakdown_k_temp.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine breakdowns (as employment in thousands) over 5 year period\n",
    "for demographic_var in demographic_vars:\n",
    "    chunks = []\n",
    "    for k in breakdown_counts.keys():\n",
    "        chunks.append(breakdown_counts[k][demographic_var])\n",
    "\n",
    "    combined_chunks = pd.concat(chunks, axis =1)\n",
    "    combined_chunks.columns = breakdown_counts.keys()\n",
    "    combined_chunks.fillna(0, inplace = True)\n",
    "    combined_chunks = combined_chunks.round(3)\n",
    "    \n",
    "    df_name = demographic_var.lower()\n",
    "    country_name = 'ita' #'uk' #'fra'\n",
    "    df_file_name = country_name+'_combined_breakdown_k'+'_'+df_name+'.'+'csv'\n",
    "\n",
    "\n",
    "    print(df_file_name)\n",
    "\n",
    "    combined_chunks.to_csv(os.path.join(eurostat_output_dir, df_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEMP</th>\n",
       "      <th>RISK_CAT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0.0</th>\n",
       "      <td>3368.821</td>\n",
       "      <td>3390.139</td>\n",
       "      <td>3462.786</td>\n",
       "      <td>3472.961</td>\n",
       "      <td>3442.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2155.867</td>\n",
       "      <td>2171.437</td>\n",
       "      <td>2163.946</td>\n",
       "      <td>2130.256</td>\n",
       "      <td>2090.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>8754.522</td>\n",
       "      <td>8806.336</td>\n",
       "      <td>9029.608</td>\n",
       "      <td>9124.980</td>\n",
       "      <td>9086.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>0.0</th>\n",
       "      <td>433.792</td>\n",
       "      <td>439.460</td>\n",
       "      <td>448.231</td>\n",
       "      <td>507.331</td>\n",
       "      <td>581.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>499.884</td>\n",
       "      <td>521.604</td>\n",
       "      <td>541.367</td>\n",
       "      <td>562.000</td>\n",
       "      <td>640.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1329.523</td>\n",
       "      <td>1408.451</td>\n",
       "      <td>1427.791</td>\n",
       "      <td>1641.795</td>\n",
       "      <td>1809.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9</th>\n",
       "      <th>0.0</th>\n",
       "      <td>1325.883</td>\n",
       "      <td>1335.883</td>\n",
       "      <td>1328.912</td>\n",
       "      <td>1282.721</td>\n",
       "      <td>1230.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>773.583</td>\n",
       "      <td>781.146</td>\n",
       "      <td>742.399</td>\n",
       "      <td>711.110</td>\n",
       "      <td>681.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3379.259</td>\n",
       "      <td>3339.863</td>\n",
       "      <td>3356.959</td>\n",
       "      <td>3329.089</td>\n",
       "      <td>3382.505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   2014      2015      2016      2017      2018\n",
       "TEMP RISK_CAT                                                  \n",
       "1    0.0       3368.821  3390.139  3462.786  3472.961  3442.556\n",
       "     1.0       2155.867  2171.437  2163.946  2130.256  2090.212\n",
       "     2.0       8754.522  8806.336  9029.608  9124.980  9086.934\n",
       "2    0.0        433.792   439.460   448.231   507.331   581.260\n",
       "     1.0        499.884   521.604   541.367   562.000   640.673\n",
       "     2.0       1329.523  1408.451  1427.791  1641.795  1809.812\n",
       "9    0.0       1325.883  1335.883  1328.912  1282.721  1230.884\n",
       "     1.0        773.583   781.146   742.399   711.110   681.558\n",
       "     2.0       3379.259  3339.863  3356.959  3329.089  3382.505"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Generate breakdowns for subnational regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra_breakdown_by_isco.csv\n"
     ]
    }
   ],
   "source": [
    "#check country\n",
    "print(country_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "country['REGION'] = country['REGION'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " 'B0',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'E1',\n",
       " 'E2',\n",
       " 'F1',\n",
       " 'F2',\n",
       " 'F3',\n",
       " 'G0',\n",
       " 'H0',\n",
       " 'I1',\n",
       " 'I2',\n",
       " 'I3',\n",
       " 'J1',\n",
       " 'J2',\n",
       " 'K1',\n",
       " 'K2',\n",
       " 'L0',\n",
       " 'M0',\n",
       " 'Y1',\n",
       " 'Y2',\n",
       " 'Y3',\n",
       " 'Y4']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(country['REGION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = 'I0'\n",
    "#Italy: Lombardy C4, Lazio I4\n",
    "#France: Ile-de-France 10 (NUTS3 FR101)\n",
    "#UK: Scotland M0, London I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = country[country['REGION'] == region_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By 3D ISCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n"
     ]
    }
   ],
   "source": [
    "reg_isco_chunks = []\n",
    "years = []\n",
    "for name, group in region.groupby('YEAR'):\n",
    "    print(name)\n",
    "    reg_isco_breakdown = group.groupby('ISCO3D')['COEFF'].sum()\n",
    "#    isco_breakdown = isco_breakdown*1000\n",
    "    reg_isco_breakdown.fillna(0, inplace = True)\n",
    "    reg_isco_breakdown = reg_isco_breakdown.round(3)\n",
    "    reg_isco_chunks.append(reg_isco_breakdown)\n",
    "    years.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jdjumalieva/miniconda3/envs/primary_3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "reg_isco_chunks_combined = pd.concat(reg_isco_chunks, axis =1 )\n",
    "reg_isco_chunks_combined.columns = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_output_file = region_name+'_breakdown_by_isco.csv'#'uk_breakdown_by_isco.csv' #'fra_breakdown_by_isco.csv'\n",
    "reg_isco_chunks_combined.to_csv(os.path.join(eurostat_output_dir, region_output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.567</td>\n",
       "      <td>0.978</td>\n",
       "      <td>4.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>24.281</td>\n",
       "      <td>24.058</td>\n",
       "      <td>25.604</td>\n",
       "      <td>21.566</td>\n",
       "      <td>61.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>98.999</td>\n",
       "      <td>115.831</td>\n",
       "      <td>110.769</td>\n",
       "      <td>146.854</td>\n",
       "      <td>119.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>69.791</td>\n",
       "      <td>77.265</td>\n",
       "      <td>76.301</td>\n",
       "      <td>80.688</td>\n",
       "      <td>69.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2014     2015     2016     2017     2018\n",
       "111     NaN      NaN    1.567    0.978    4.206\n",
       "112  24.281   24.058   25.604   21.566   61.141\n",
       "121  98.999  115.831  110.769  146.854  119.652\n",
       "122  69.791   77.265   76.301   80.688   69.668\n",
       "131     NaN      NaN      NaN    0.937      NaN"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_isco_chunks_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for all demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "SEX\n",
      "True\n",
      "126.81963217417317 2.8937884231616828e-28\n",
      "AGE\n",
      "False\n",
      "nan nan\n",
      "REGION\n",
      "True\n",
      "0.0 1.0\n",
      "NACE1D\n",
      "False\n",
      "nan nan\n",
      "HATLEV1D\n",
      "True\n",
      "460.49631977776244 2.336538693929838e-98\n",
      "INCDECIL\n",
      "True\n",
      "406.83590434400406 7.798246025409434e-74\n",
      "NATIONAL\n",
      "False\n",
      "nan nan\n",
      "FTPT\n",
      "True\n",
      "78.31334333842307 9.873555332888645e-18\n",
      "TEMP\n",
      "True\n",
      "49.21226883925394 5.272731074955377e-10\n",
      "2015\n",
      "SEX\n",
      "True\n",
      "127.17990115837009 2.416770209638365e-28\n",
      "AGE\n",
      "False\n",
      "nan nan\n",
      "REGION\n",
      "True\n",
      "0.0 1.0\n",
      "NACE1D\n",
      "False\n",
      "nan nan\n",
      "HATLEV1D\n",
      "True\n",
      "596.7063512222509 7.999190569774163e-128\n",
      "INCDECIL\n",
      "True\n",
      "402.27336664116086 6.900540625982267e-73\n",
      "NATIONAL\n",
      "False\n",
      "nan nan\n",
      "FTPT\n",
      "True\n",
      "49.20081628731281 2.0709923308208866e-11\n",
      "TEMP\n",
      "True\n",
      "34.439122494972366 6.05588310858137e-07\n",
      "2016\n",
      "SEX\n",
      "True\n",
      "84.05259325976137 5.600299827910657e-19\n",
      "AGE\n",
      "False\n",
      "nan nan\n",
      "REGION\n",
      "True\n",
      "0.0 1.0\n",
      "NACE1D\n",
      "False\n",
      "nan nan\n",
      "HATLEV1D\n",
      "True\n",
      "604.7957124234227 1.4200126578168812e-129\n",
      "INCDECIL\n",
      "True\n",
      "522.7639708619542 4.9444767162272535e-98\n",
      "NATIONAL\n",
      "False\n",
      "nan nan\n",
      "FTPT\n",
      "True\n",
      "71.6790313284414 2.723303930969881e-16\n",
      "TEMP\n",
      "True\n",
      "36.32390703250296 2.4820103582030314e-07\n",
      "2017\n",
      "SEX\n",
      "True\n",
      "81.78116837511483 1.7435922321978908e-18\n",
      "AGE\n",
      "False\n",
      "nan nan\n",
      "REGION\n",
      "True\n",
      "0.0 1.0\n",
      "NACE1D\n",
      "False\n",
      "nan nan\n",
      "HATLEV1D\n",
      "True\n",
      "768.1063743824968 6.213563886293087e-165\n",
      "INCDECIL\n",
      "False\n",
      "nan nan\n",
      "NATIONAL\n",
      "False\n",
      "nan nan\n",
      "FTPT\n",
      "True\n",
      "96.37480333810267 1.1816187067531571e-21\n",
      "TEMP\n",
      "True\n",
      "70.89552930409782 1.468595908468582e-14\n",
      "2018\n",
      "SEX\n",
      "True\n",
      "81.2629259203111 2.2593309140868604e-18\n",
      "AGE\n",
      "False\n",
      "nan nan\n",
      "REGION\n",
      "True\n",
      "0.0 1.0\n",
      "NACE1D\n",
      "False\n",
      "nan nan\n",
      "HATLEV1D\n",
      "True\n",
      "701.0829518435194 2.0311776105326253e-150\n",
      "INCDECIL\n",
      "True\n",
      "481.2005668935424 2.4946611432803977e-89\n",
      "NATIONAL\n",
      "False\n",
      "nan nan\n",
      "FTPT\n",
      "True\n",
      "71.13567049024519 3.573431157558119e-16\n",
      "TEMP\n",
      "True\n",
      "67.5733933242285 7.379675545864634e-14\n"
     ]
    }
   ],
   "source": [
    "#Define output dicts for storing results\n",
    "reg_breakdown_props = collections.defaultdict(dict)\n",
    "reg_breakdown_counts = collections.defaultdict(dict)\n",
    "reg_chi_square_res = collections.defaultdict(dict)\n",
    "\n",
    "#Iterate over files in the folder\n",
    "for name, group in region.groupby('YEAR'):\n",
    "    print(name)\n",
    "    for demographic_var in demographic_vars:\n",
    "        print(demographic_var)\n",
    "        reg_breakdown_count, reg_breakdown_prop = demo_breakdown(group, demographic_var, 'RISK_CAT', 'COEFF')\n",
    "        reg_breakdown_counts[name][demographic_var] = reg_breakdown_count\n",
    "        reg_breakdown_props[name][demographic_var] = reg_breakdown_prop\n",
    "\n",
    "        breakdown_p = pivot_breakdown(reg_breakdown_count, 'COEFF', demographic_var, 'RISK_CAT')\n",
    "        check_condition = (breakdown_p >=5).all(axis = 1).all()\n",
    "        print(check_condition)\n",
    "\n",
    "        if check_condition:\n",
    "            stat, p, dof, expected = chi2_contingency(breakdown_p.values)\n",
    "\n",
    "        else:\n",
    "            stat = np.nan\n",
    "            p = np.nan\n",
    "\n",
    "        print(stat,p)\n",
    "        reg_chi_square_res[name][demographic_var] = (stat, p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "counts_name = region_name+'_'+'breakdown_counts.pkl'\n",
    "props_name = region_name+'_'+'breakdown_props.pkl'\n",
    "chi_square_name = region_name+'_'+'chi_square_res.pkl'\n",
    "\n",
    "\n",
    "with open(os.path.join(eurostat_output_dir, counts_name), 'wb') as f:\n",
    "    pickle.dump(reg_breakdown_counts, f)\n",
    "\n",
    "with open(os.path.join(eurostat_output_dir, props_name), 'wb') as f:\n",
    "    pickle.dump(reg_breakdown_props, f)\n",
    "    \n",
    "with open(os.path.join(eurostat_output_dir, chi_square_name), 'wb') as f:\n",
    "    pickle.dump(reg_chi_square_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_sex.csv\n",
      "10_age.csv\n",
      "10_region.csv\n",
      "10_nace1d.csv\n",
      "10_hatlev1d.csv\n",
      "10_incdecil.csv\n",
      "10_national.csv\n",
      "10_ftpt.csv\n",
      "10_temp.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine breakdowns for proportions\n",
    "for demographic_var in demographic_vars:\n",
    "    chunks = []\n",
    "    for k in reg_breakdown_props.keys():\n",
    "        chunks.append(reg_breakdown_props[k][demographic_var])\n",
    "\n",
    "    combined_chunks = pd.concat(chunks, axis =1)\n",
    "    combined_chunks.columns = reg_breakdown_props.keys()\n",
    "\n",
    "    df_name = demographic_var.lower()\n",
    "    df_file_name = region_name+'_'+df_name+'.'+'csv'\n",
    "\n",
    "\n",
    "    print(df_file_name)\n",
    "\n",
    "    combined_chunks.to_csv(os.path.join(eurostat_output_dir, df_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_sex_k.csv\n",
      "10_age_k.csv\n",
      "10_region_k.csv\n",
      "10_nace1d_k.csv\n",
      "10_hatlev1d_k.csv\n",
      "10_incdecil_k.csv\n",
      "10_national_k.csv\n",
      "10_ftpt_k.csv\n",
      "10_temp_k.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine breakdowns for counts (employment in thousands)\n",
    "for demographic_var in demographic_vars:\n",
    "    chunks = []\n",
    "    for k in reg_breakdown_counts.keys():\n",
    "        chunks.append(reg_breakdown_counts[k][demographic_var])\n",
    "\n",
    "    combined_chunks = pd.concat(chunks, axis =1)\n",
    "    combined_chunks.columns = reg_breakdown_counts.keys()\n",
    "    combined_chunks.fillna(0, inplace = True)\n",
    "    combined_chunks = combined_chunks.round(3)\n",
    "    \n",
    "    df_name = demographic_var.lower()\n",
    "    df_file_name = region_name+'_'+df_name+'_k'+'.'+'csv'\n",
    "\n",
    "\n",
    "    print(df_file_name)\n",
    "\n",
    "    combined_chunks.to_csv(os.path.join(eurostat_output_dir, df_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Check significance for chi-square test for a given variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# France\n",
    "# with open(os.path.join(eurostat_output_dir, 'all_prop_demo_breakdown', 'fra_chi_square_res_r.pkl'), 'rb') as f:\n",
    "with open(os.path.join(eurostat_output_dir, '', 'fra_chi_square_res_r_KK.pkl'), 'rb') as f:\n",
    "    fra_chi_square = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499840.77100020554, 0.0)\n",
      "(417213.26518200483, 0.0)\n",
      "(551292.139385549, 0.0)\n",
      "(467488.1710338946, 0.0)\n",
      "(529749.4657162151, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# demographic_vars = ['SEX', 'AGE', 'REGION', 'NACE1D', 'HATLEV1D','INCDECIL', 'NATIONAL', 'FTPT', 'TEMP']\n",
    "demo_var = 'NATIONAL'\n",
    "for k in fra_chi_square:\n",
    "    print(fra_chi_square[k][demo_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italy\n",
    "with open(os.path.join(eurostat_output_dir, 'all_prop_demo_breakdown', 'ita_chi_square_res_r.pkl'), 'rb') as f:\n",
    "    ita_chi_square = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1284.1033523011054, 7.498732717806765e-260)\n",
      "(1262.4839257160058, 3.186581351538294e-255)\n",
      "(1188.360553708729, 2.306230634126418e-239)\n",
      "(1105.9221776772379, 9.63057236392359e-222)\n",
      "(1105.437292131926, 1.2224544762533198e-221)\n"
     ]
    }
   ],
   "source": [
    "demo_var = 'INCDECIL'\n",
    "for k in ita_chi_square:\n",
    "    print(ita_chi_square[k][demo_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK\n",
    "with open(os.path.join(eurostat_output_dir, 'all_prop_demo_breakdown', 'uk_chi_square_res_r.pkl'), 'rb') as f:\n",
    "    uk_chi_square = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515.5678816590101, 9.713525533738354e-94)\n",
      "(523.2752145609305, 2.423011948604621e-95)\n",
      "(513.9229183887859, 2.1348679218602766e-93)\n",
      "(414.3936021187407, 8.283211854651931e-73)\n",
      "(458.3499213231952, 7.120740477140461e-82)\n"
     ]
    }
   ],
   "source": [
    "demo_var = 'AGE'\n",
    "for k in uk_chi_square:\n",
    "    print(uk_chi_square[k][demo_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
